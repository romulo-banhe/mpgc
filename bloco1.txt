Sou formado em administração de empresas pela Fundação Getúlio Vargas, pela Escola de Administração de Empresas de São Paulo, formado em 2007, depois eu trabalhei no mercado financeiro e aí eu sempre trabalhei, na verdade, com, de alguma forma, com manipulação, captura de dados, então seja via a Lei Planilha Excel, depois você aprende a fazer algum tipo de programação no VBA, depois fui me interessando cada vez mais por esses temas relacionados à transformação de dados em informação, e aí eu fui migrando gradativamente minha carreira para a área de dados, ao fazer alguns cursos, depois uma pós-graduação em inteligência artificial e machine learning, culminando num mestrado em data science na New York University, finalizado em 2023, e concomitante a tudo isso eu também fiz a transição da carreira privada para a carreira pública, onde eu ingressei na empresa em 2014, me encontro lá desde então, e hoje atuo como Head de dados e Inteligência Artificial, na verdade a parte de dados aí é só a parte de utilização de dados, toda a parte de arquitetura de dados, engenharia de dados, a parte de, digamos assim, do plano de como os dados são armazenados e tudo mais, isso aí diz respeito à coordenadoria de tecnologia, que não é a área em que eu estou, mas a gente, eu estou representando hoje todas as áreas de negócio na empresaƒ que utilizam dados, então, e toco os projetos de inteligência artificial, a maior parte deles relacionados à Generative AI. Legal, legal, legal, muito bom.Olha, com certeza, pelo que eu tenho visto do público, né, porque a gente conversa com muita gente da área pública, são instrumentos de Generative AI, né, com certeza é o que mais tem, o que eu mais tenho visto, por exemplo, é a utilização para a gestão de base de conhecimento, então, por exemplo, em tribunais judiciais e até mesmo tribunais de contas, tem-se utilizado muito as LLMs para a captura de informação dentro de um corpus ali, de um banco de dados existente, e da mesma forma a gente tem seguido por esse caminho, né, o que acontece é que no setor público você tem muito dados e você tem muito dados textual, né, e você tem muitas atividades relacionadas à sumarização desses dados, captura dos principais pontos, etc. Então, quer dizer, é basicamente o trabalho que uma LLM sabe fazer muito bem, né.Agora, no campo de inteligência artificial e machine learning em geral, aí já é um pouco mais restrito, aí eu vejo uma ou outra aplicação, mas de uma forma mais pontual, né.Olha, apesar da gente estar construindo algumas aplicações de inteligência artificial, como eu disse, a nossa, se você observar a empresa, o desenvolvimento dela ao longo da curva de maturidade de dados, por exemplo, né, ela não é linear, o que significa que em algumas áreas, alguns contextos, a parte de dados está muito fraca, né, está ainda muito no começo dessa curva, em outras áreas ela está super avançada, né.Então, por exemplo, voltando à questão da gestão de conhecimento, com aplicações de AI, de Generative AI, a gente está muito avançado nesse tópico, e aí todos os dados estão organizados, etc., né, catalogados, muito bem armazenados, etc. Já em outras partes, a gente não consegue nem muito bem manipular esses dados, quem dirá fazer qualquer tipo de utilização relacionada à inteligência artificial, porque a política de dados, ela não foi seguida, digamos que linearmente, em todas as áreas, em todas as utilizações dentro da empresa, né. Então, ainda tem muita desigualdade ali, né, tem muito, não foi uma adoção linear.Então, por exemplo, quando a gente fala de nota fiscal de serviço, eletrônico, isso é uma base de dados que se você pegar as notas emitidas nos últimos cinco anos, tem 13 bilhões de linhas. Então, isso a gente não consegue nem fazer uma query simples de agregação que demore menos de uma hora. Então, aí a gente ainda está analisando, puxa, como é que a gente vai fazer para, por exemplo, virtualizar essa base de dados, jogar numa cloud, usar algum tipo de estratégia de um parceiro, como da Microsoft, por exemplo, para acelerar a obtenção de dados agregados relacionados a essa base de dados.Isso em um campo específico, né. Então, em suma, há um desnivelamento muito grande a depender do tipo de dados e dependendo do tipo de uso na nossa organização.Olha, eu acho que, primeiro de tudo, é o volume de dados que a gente trabalha, né. Então, assim, o setor público captura muitos dados, né. Então, imagina que a gente está capturando a cada segundo todas as notas fiscais de serviço e eletrônicas emitidas.Então, assim, é muita coisa, né. Então, a gente tem dados de todos os imóveis, por exemplo, de todos os comerciais e residenciais. A gente tem dados de todas as transações imobiliárias realizadas na cidade.Então, assim, o primeiro grande entrave aqui que a gente fala sempre é o volume de dados, né. A gente sempre trabalha com big data por concepção, assim, né. Segundo de tudo é que a gente teve, durante muito tempo, uma certa, digamos, um certo preconceito com relação a utilizar soluções que transcendessem o nosso ambiente físico ali, né.Então, durante muito tempo a gente ficou com a ideia de que a gente tinha que manter isso nos nossos mainframes, nos nossos servidores e tudo mais, que não poderia utilizar a cloud até a gente começar a ganhar níveis de confiança com a cloud, a gente começar a ter provas de que a cloud funcionava muito bem em termos de segurança. E aí, sim, a gente começou a adotar as soluções de cloud computing, né. E aí, junto com o cloud computing, também você tem ali acesso às soluções mais robustas do mercado, né.Então, já é um facilitador muito grande. E eu acho que esses são os dois principais, né. A volumetria dos dados ali e a questão relacionada a algum tipo de preconceito quanto à utilização de técnicas de parceiros, né, de melhores ferramentas dos parceiros que ajudam muito, né.Tenho pouco mais de 20 anos de experiência de mercado em tecnologia.Tive passagens por áreas de sistema, infraestrutura, segurança da informação; liderei torres de atendimento para o negócio; fui também responsável por um centro de serviço compartilhado; assumi um posto que não era diretamente ligado à tecnologia, mas ligado a processos de negócio, sendo diretor de um centro de serviço compartilhado. Atuo há cerca de 17 anos no ramo de concessão de serviços de infraestrutura. Já atuei com diversos segmentos: rodovia, mobilidade urbana, aeroportos. Também já fiz implantação de escritório de projetos e, hoje, aqui na empresa, eu sou responsável por tudo o que é tecnologia, incluindo os escopos de infraestrutura, segurança da informação,dados, sistemas, aplicações, integração, arquitetura.Então, todos esses escopos aqui são de responsabilidade nossa, aqui na empresa.Olha, por vários fatores, entre eles a complexidade e a granulidade das aplicações, eu acho que tecnologias mais relacionadas à integração têm evoluído muito e se unido ao cloud computing. Então, no passado, a gente tinha plataformas on-premises de integração robustas; atualmente, essas plataformas já rodam em nuvem; já tem grandes plataformas de integração funcionando muito bem, serviços em nuvem. Vou conectar aqui já com observabilidade, que é outro ponto que, independente se você está rodando no on-premise, se você está rodando em nuvem, é cada vez mais importante nós, como tecnologia, conseguirmos dimensionar o consumo, além de manter tudo rodando, que acho que isso é o business “As usual” já, é a nossa obrigação, como um colega meu dizia, eu preciso, como tecnologia, conseguir dimensionar os recursos e conseguir medir o quanto de recursos as aplicações de negócio estão consumindo, para eu conseguir, independente se você vai ter um chargeback ou não, voltar para ele e falar, você vai pagar pelo tanto que você consumiu, que acho que essa é uma outra discussão, mas eu tenho que conseguir mostrar para ele quanto é que está custando o quanto você consumiu, porque senão todo custo fica como responsabilidade da tecnologia.E aí a tecnologia acaba custando cada vez mais, e a gente acaba sendo visto só como um centro de custo, e isso, do ponto de vista de estratégia, é muito ruim. Então, observabilidade, tanto do ponto de vista de monitoramento e garantia da disponibilidade, monitorar, ser orientado a evento, toda aquela questão que vem dos modelos conceituais, de como a gente monta as arquiteturas e como a gente monitora, mas também do ponto de vista de negócio, para conseguir medir o consumo, como é que estou consumindo os recursos, olhando as aplicações, olhando os processos de negócio que estão por trás das aplicações. Eu ia comentar um pouco sobre dados de IA também. Para fechar, acho que dados e inteligência artificial, voltados a eles, têm muito potencial. O conceito de utilização de dados vem mudando ao longo do tempo, porque a quantidade de dados vem aumentando cada vez mais. Então, lá atrás, você falava de modelos voltados a BI, Data Warehouse e Data Marts; era um conceito. Isso evoluiu. Você fala de Data Lake, dados não estruturados. Você trabalha com dados estruturados e não estruturados. Hoje você tem modelos mais avançados para análise de dados.Tem um problema aí no meio, que eu acho que é o quanto as empresas estão com dados prontos para serem utilizados, que é algo que tem um certo nível de maturidade aqui. A gente tem tentado disseminar isso para democratizar o uso de soluções de BI, de Analytics, para que isso fique na mão das áreas de negócios. E inteligência artificial é algo que, apesar de estar crescendo muito, tem um potencial enorme. Tem o dados do Gartner lá: 40% dos projetos de inteligência artificial vão ser cancelados. Isso mostra que as empresas, todo mundo quer, mas que ainda não está tão pronto do ponto de vista de processo, ainda não está tão pronto do ponto de vista de dados, e o Gartner traz essa questão que tem as duas corridas, tem a corrida do vendor, que o cara sempre vai falar que está pronto, sempre vai falar que aquilo está atrasado, se você não fizer agora e tal, e tem a corrida nossa, das empresas, que no fundo é o bottom line, então você precisa mostrar resultados, você precisa conseguir mostrar aplicação prática, retorno, valor agregado. Olhando nossa corrida, também tem a questão de segurança, porque, você queira ou não, se você está montando, construindo uma RFP de AMS de um determinado processo seu, super estratégico para a sua empresa, e você está usando o ChatGPT para tudo lá, como é que eu faço, como é que eu estruturo, montando lá, fazendo seus prompt, bacana para caramba, no final, você está fazendo o payload da sua estratégia lá dentro, colocando questões estratégicas para a inteligência artificial te ajudar, beleza. Só que aí, a inteligência artificial é pública, então pensa que os players que vão concorrer também estão acessando essa mesma inteligência artificial. O cara pode pedir as informações lá dentro, e lá dentro vão ter suas informações estratégicas. Como é que você vai analisar tudo mais? Então tem que tomar muito cuidado, para a gente também, do ponto de vista empresarial, se proteger um pouco com a utilização.Então, a gente, como tecnologia, tem um papel muito difícil, porque, ao mesmo tempo em que você vai querer proteger as áreas de negócio, vão dizer que você está pondo barreiras e não está deixando as áreas usarem a inteligência artificial. Por outro lado, tem essas questões de segurança e de exposição, bem como informações estratégicas, que a base pública vai botar lá dentro.Mas assim, fazendo um apanhado geral, acho que essas são as principais tecnologias que eu vejo, que têm potencial e que a gente, de alguma forma, tem algum nível de maturidade dentro, mas que têm também seus desafios.Processos. Aqui na empresa, em específico, os nossos processos são antigos. É uma empresa que tem uma característica conservadora por natureza, pelas questões de segurança operacional e tudo mais. Então, ela tende a ser mais conservadora. Então, os processos são antigos; vamos dizer, não são processos tão modernos.Então a gente está provocando agora para revisitar a cadeia de valor, rediscutir e redesenhar o processo e tudo mais. Então, assim, os processos não redondos, ou muito engessados, enfim, muito customizados, trazem um dificultador. A qualidade dos dados é outro dificultador, na minha visão, porque um dados ruim gera uma informação ruim.Então, isso é uma questão que, na hora em que você está construindo uma lógica para extrair informação e construir algo junto com uma inteligência artificial, se o dados que você está submetendo à inteligência artificial para análise não for bom, a resposta que a gente vai obter pode ser questionável. E, se você olhar as inteligências artificiais hoje, elas erram facilmente. Ela erra facilmente e você responde para ela lá: “Não era isso. Ela fala: você está correto. Me desculpa. A informação correta é esta outra.Então a gente tem que tomar cuidado com isso, né? Acho que o desafio é fazer com que as pessoas entendam que a inteligência artificial não pode deixar a gente mais preguiçoso. A gente vai ter que continuar validando o que vem. A gente precisa continuar responsável pelo que vem. Não é só pegar aquilo e mandar adiante. Então tem que tomar muito cuidado.E o terceiro que eu colocaria aqui é a questão da segurança.Eu vou falar que a minha primeira experiência foi no Exército. Eu vou citar porque acho que me ajudou muito o Exército. Eu acho que eu fiquei logo quando eu fiz 18 anos, eu não queria servir, mas eu acabei ficando no ano obrigatório, eu já tinha passado no curso de ciência da computação, e o que aconteceu, né, eu tive a oportunidade que eles chamam de engajar, ficar por mais tempo, então eu acho que como a minha família não tinha nenhuma condição de custear minha faculdade, eu fiquei com medo de não ter um trabalho e ter que parar de estudar, e aí eu fiquei, mas aí eu coloquei como meta, no quarto ano da faculdade eu saio, porque se eu deixar de pagar, não tem problema nenhum,  pelo menos eu completo o estudo, e depois eu dou um jeito de pagar. Mas eu acho que, porque que eu falo o Exército, eu acho que ele me ajudou a ter uma uma casca, uma questão de perseverança, de poder vencer as dificuldades, porque eu falo que eu depois, consegui entrar no mercado, então eu falo que eu ainda estou, assim, ainda vivo muito isso, mas eu falo que eu me especializei em ambientes de missão crítica e fazer troubleshooting, resolver problema, resolver problema de tecnologia, e, né, acho que passei por, tive oportunidade também de, de um modo geral, a trabalhar em grandes empresas, ou diretamente, ou por terceiros. Então, isso me ajudou muito também, essa diversidade, me ajudou muito também, tanto de resolver problema muito próximo do negócio, e essa diversidade de negócio em si, um era Telecom, outro era a questão de tecnologia, outra a questão de varejo, com foco em cosmético, e isso me levou nessa oportunidade, eu sempre tive muito interesse na parte de dados, de analítica, sempre com a questão de entender o porquê das coisas, então, mais baseado em dados, então, eu tô com essa oportunidade, comecei na empresa como head de dados essa eu vou falar que é uma oportunidade que eu tô, vamos falar assim, 100% com dados, nas outras eu não estava.A empresa, ela vem crescendo bastante, e ela, principalmente, ela foi impulsionada, eu acho, pela qualidade do produto, ela fabrica o produto, então, acho que, primeiro, começa com essa otimização de fábrica mesmo, de linha de produção, e com esse crescimento, com a vinda do meu diretor, que ele cuida da área de tecnologia, ele traz a transformação digital, que faz, mais ou menos, uns dois anos, temos frentes de melhorar os dados, e, desde então, ele vem com várias frentes de mudança, então, por exemplo, de uma implementação de CRM, uma ferramenta robusta, em várias frentes, atualização da parte do ERP de fábrica, melhorar os processos de fábrica, onde que tem tecnologia, atualização do nosso ERP, a parte de dados, inclusive, implementar a questão de fazer uma jornada de dados, começar com data mesh, movimento para cloud, então, toda essa mandala, vamos falar assim, ele puxou e estamos atuando agora, então, eu diria que não seria uma frente, mas a gente está com várias frentes, para poder alavancar de forma rápida e com tecnologia.Eu vou chamar de, eu vou sugerir uma aqui,  porque o pessoal fala de cultura data-driven; eu vou falar que a gente está numa cultura tech-driven. Eu acho que é movida por tecnologia. Eu acho que, como a empresa, historicamente, tem coisas que acontecem positivas que às vezes reforçam o negativo. Qual é o ponto?Onde eu quero chegar? Meu, olha como a gente está crescendo aqui, como que vocês querem mudar a nossa forma de trabalhar, eu não preciso de uma ferramenta de tecnologia, então, isso gera, de certa forma, um desafio, uma dificuldade, implementar as soluções, então, o receio de aderir à tecnologia, talvez um receio, de repente, até às vezes, de perder um emprego, por exemplo, tá, o que eu estou fazendo agora, um software vai fazer, mas como vai ser minha vida? Então, a gente tá nessa evangelização tecnológica, né? Então, a gente tem um grande desafio, não encontramos resistência, mas é um caminho mais lento.Ah, meu ponto de vista, eu acho que é uma, talvez, uma limitação de visão, eu acho não ter uma, de repente, uma visão externa, de um modo geral, com uma visão externa de tecnologia, de como ela traz, de repente, de olhar cases, de como que funcionou, então, assim, com esse novo diretor, ele vem trazendo, eu vou falar assim, essa luz, eu vou chamar de luz, vem trazendo, assim, esse conhecimento, vem falando, porque ao mesmo tempo que você implementa, por exemplo, que nem eu te falei, tanto uma nova estrutura de dados, uma nova arquitetura, um novo ERP, novo CRM, remodelando a fábrica, você, talvez, por osmose, você começa a disseminar tecnologia nova, então, é, eu acho que com isso, a gente começa a trazer, também, os próprios fornecedores, que estão implementando, para poder fazer essa evangelização.Bom, eu tenho 25 anos de TI. Comecei no início dos anos 2000 como desenvolvedor Delphi e, em 2002, virei a chave e migrei para o mundo SAP.Comecei a trabalhar como consultor, função que exerci até 2010 ou 2011, quando entrei no grupo grande de concessões. Nesta empresa, assumi uma posição de liderança, depois passei pela coordenação e cheguei à gestão executiva.Atualmente em uma grande industria de transportes, assumi o papel de CIO, e sou o responsável integral por todos os aspectos relacionados à tecnologia da informação, transformação digital, etcÉ, quando olhamos para ERP, não temos como não falar do SAP. Eu acho que o SAP hoje... não sei se você sabe, mas 90% do PIB mundial passa pelo SAP. Então, os caras hoje praticamente dominam o mundo.Então, quando a gente fala de tecnologias emergentes voltadas não só para o ERP, eles têm agora um conglomerado de produtos conectados. O ERP, lógico, é o core.Mas, nesse mundo atual, o hype é a inteligência artificial, então eles estão vindo com o produto deles, que é o Joule*. E tem o BTP, enfim, tem uma série de soluções que estão interligadas, dentro dessa rede que é o ERP.Aí, por exemplo, quando você olha para a infraestrutura, já é um outro mundo. Na conectividade, por exemplo, você tem muito forte a Cisco, Huawei. Acho que são equipamentos e produtos muito conceituados no mercado; HP também.O que eu tenho visto agora em infraestrutura é que eles estão olhando para micro serviços e small business para poder baratear.Porque, por exemplo, lá na concessionária de infraestrutura onde eu trabalhava, você tinha unidades de negócio altamente rentáveis, mas também tinha unidades em nível de startup. Aqui na empresa também é assim: você tem unidades muito rentáveis e outras unidades de negócio muito pequenas.Então, fica complicado você trazer um equipamento, um AP Cisco, por exemplo, para um small business.Quando você faz um business case trazendo o escopo inteiro de TI para um negócio pequeno, isso não para em pé. Então, eles estão olhando muito para essa questão de small business.Mas existe também a questão da conectividade cloud agora; a Equinix, por exemplo, está vindo muito forte com essa abordagem. A infraestrutura é, digamos, o alicerce para se ter ambientes seguros e ser pautado em segurança da informação.E quando você olha para segurança da informação, também há um aparato de soluções, desde MFA até toda a eficiência de disaster recovery. Enfim, é muito amplo.Quando se fala em 'tecnologias emergentes', há muita coisa forte no mercado hoje. Olhando para dados, por exemplo, você tem o Databricks que está muito forte, mas a SAP também tem o Datasphere. Só que os dois fecharam uma parceria recentemente; antes eles eram concorrentes.Hoje, eles ainda são concorrentes, mas estão com um pacote interessante nas conexões de Datasphere com o Databricks. Quando você olha para inteligência artificial, temos os principais LLMs, como o OpenAI e o Gemini.Olhando todo esse contexto, eu lembro que, quando comecei na área de tecnologia, era fácil fazer um planejamento estratégico porque você tinha poucas opções. Era 'Windows e tal', era simples.Hoje em dia, é muito difícil fazer um planejamento estratégico e saber exatamente onde investir. Você tem muitas opções de tecnologias emergentes. Enfim, não sei se consegui responder.Ah, eu vejo que esse é um outro desafio. Hoje tem evento para todos os gostos; a palavra 'Summit', praticamente, virou moda no mercado.E eu sinto muita dificuldade na adoção, porque a venda e a pré-venda são muito fortes. Inclusive, as empresas, esses grandes players de mercado, estão agora mensurando o resultado das suas áreas comerciais não pela venda, não pelo resultado comercial, mas sim pela adoção.Isso ocorre justamente porque há uma dificuldade gigantesca de adoção. Eu vou te dar um exemploA gente implementou recentemente o S4HANA. Fizemos um modelo Brownfield, que é converter o ECC, simplesmente, sem olhar para as novas funcionalidades. Apenas converter.Depois disso, criamos uma jornada de adoção das novas funcionalidades. O GoLive foi na virada de 2023 para 2024. Praticamente, usamos 2024 para preparar o ambiente, pois existia uma série de requisitos para isso.Embora já estivéssemos no S4HANA, muitas funcionalidades não estavam disponíveis porque eu tinha que preparar o ambiente; havia uma série de requisitos técnicos. Então, em 2024, fizemos isso.Em 2025, começamos a olhar para a jornada evolutiva do S4HANA. Mas aí descobrimos que a versão em que estamos não tem tantas funcionalidades assim e que teríamos que fazer uma nova conversão de versão.Estou dando o exemplo do S4HANA, mas posso trazer tantos outros. O BTP, por exemplo, é outro produto da SAP com muitas funcionalidades, mas a gente tem muita dificuldade de adoção.Saindo do SAP e indo para a Microsoft: fizemos uma jornada aqui de inteligência artificial e determinamos que, na fase inicial, a ferramenta padrão para a empresa seria o Copilot.Fizemos toda uma jornada de letramento, adoção, conscientização, desenho de política e modus operandi para governança. Criamos todo um contexto. E quando vamos olhar o resultado efetivo daquilo, o ROI não foi tão grande assim.Então, apesar de o assunto estar super em alta, temos uma certa dificuldade. Eu sinto que esses grandes players, como Microsoft e SAP, também não sabem como nos ajudar a conseguir eficiência na adoção.Eu vejo que esse é um desafio e, participando de grupos de CIOs do Brasil e aqui do Rio Grande do Sul, percebo que esse é um desafio de todos eles.Eu acho que falta o preparo das pessoas em entender que inovar não é (apenas) a adoção tecnológica em si, mas sim olhar as vulnerabilidades, as ineficiências e as dores do dia a dia.As pessoas têm muita dificuldade de mapear onde estão as oportunidades. Vou dar um exemplo: aqui na montadora, a empresa que fabrica carretas, vemos muito forte que o entendimento deles de inovação está relacionado a plugar o maior número de startups possíveis na rede, ou trazer o maior número de RPAs e Power BIs conectados.Eu vejo que essa questão de explorar as dores e as ineficiências acaba ficando para trás. As pessoas não olham muito para isso. Ao meu ver, elas deveriam ter um pouco de metodologia e métrica para explorar isso primeiro, para depois entender o que precisam e fazer adoções coerentes.Além disso, existem também os desafios técnicos no meio do caminho. Como eu disse, implementamos o S4HANA, mas, quando começamos a trilhar a jornada de adoção, nos deparamos com uma série de requisitos técnicos e configurações de ambiente. E nem a SAP tinha visibilidade disso.Então, talvez esses grandes players ainda precisem entrar um pouco mais a fundo na nossa realidade, para nos dar o direcionamento correto e termos maior eficiência na adoção.Fiz ciências da computação na graduação e fiz processamento de dados no ensino médio. Comecei a me interessar pela área de tecnologia fazendo aqueles cursos que, na época, existiam nos bairros e eram anunciados nas escolas. Eu tinha cerca de 13 ou 14 anos. Na minha escola apareceu alguém oferecendo cursos de programação, e a gente nem sabia exatamente o que era isso, porque era um período em que isso não era comum. Por conta dessa oferta inesperada, com 14 anos eu já estava fazendo um curso para programar em Cobol. Essa foi a minha entrada na área de tecnologia.A partir daí, fui fazer o colegial de IPD no ensino médio, depois ciências da computação, e desde então entrei para a área de tecnologia. Já no primeiro ano da faculdade, como eu tinha experiência prévia em programação, algo incomum para os jovens no início da graduação, acabei fazendo estágio logo no primeiro ano. Iniciei minha trajetória em desenvolvimento. À medida que a carreira evolui, a gente vai assumindo posições mais de gestão e, em algum momento, senti necessidade de fazer uma pós na área de administração. Fiz uma pós lato sensu, depois o mestrado em administração e, em seguida, o doutorado em administração. No doutorado, estudei na FGV, com concentração em TDS, em tecnologia, e sigo até hoje nessa área.Na minha carreira profissional, em paralelo à trajetória acadêmica, comecei na área de desenvolvimento e, conforme fui avançando, assumi posições de liderança e passei por todas as áreas de tecnologia. Atuei com desenvolvimento, infraestrutura, suporte, área de dados e, como executiva, como CIO de uma organização maior. Ao longo dessa trajetória trabalhei em grandes empresas. Trabalhei na Hertz, na Raider, na SGD, que era um spin-off do grupo Sangobank e depois virou Veresense. Grande parte da minha carreira estive em áreas de tecnologia dentro de empresas do segmento industrial, não por escolha intencional, mas porque foi o que aconteceu naturalmente.No final do doutorado, eu estava na Veresense como executiva de TI, responsável por toda a área de tecnologia da empresa no Brasil. A Veresense é uma empresa francesa. Naquele período final, eu já tinha sido bastante influenciada pela academia e estava circulando muito nesse ambiente. Eu também queria fazer o doutorado sanduíche no exterior. Então, no final do doutorado, saí da empresa, fui para o Canadá fazer o sanduíche e, quando voltei, já tinha fundado a OCTO, uma consultoria que apoia empresas em jornadas de dados e transformação digital.Por meio da OCTO, consegui ter flexibilidade para atuar em diferentes frentes. Hoje me divido em três áreas. Na OCTO, continuo trabalhando com empresas, prestando consultoria para grandes organizações. Também mantenho um braço acadêmico, pesquisando, escrevendo e dando aula quando possível. E tenho um braço voltado para startups. Sou membro do FGV Angels, o grupo de investidores-anjo da fundação de ex-alunos da FGV. Sou membro de outra rede de anjos chamada Sororité, que investe em startups lideradas por mulheres. Agora estou fundando uma startup também e atuo nesse ecossistema.Eu acho que, nos últimos anos, não tem como não falar de IA, porque é algo presente em todas as discussões. Tornou-se essencial. Houve um movimento inicial muito difícil, especialmente para as pessoas de tecnologia, porque muitos profissionais relatavam que diretores e gestores queriam implementar IA nas empresas simplesmente porque tinham ouvido alguém comentar sobre o tema. Contudo, não sabiam para quê. Procuravam a área de tecnologia dizendo que era necessário usar IA. Quando questionados sobre o objetivo, respondiam que não sabiam e que a área de tecnologia deveria definir.Assim, a área de tecnologia se via diante da necessidade de aplicar uma tecnologia sem que houvesse maturidade nas áreas de negócio para entender o propósito de uso. Esse foi um primeiro momento que enfrentamos com AI. Acredito que isso está melhorando e amadurecendo. As empresas estão começando a entender a dimensão dos riscos de determinadas soluções para determinados usos, bem como as implicações do seu emprego. Também estão percebendo a dificuldade de implementação, porque quando o fornecedor apresenta a solução, parece que tudo é simples e automatizado, como se o modelo realmente aprendesse sozinho. Mas existe trabalho envolvido para que isso aconteça.As empresas estão reconhecendo essa complexidade, entendendo melhor o processo, e, com isso, os projetos estão amadurecendo. Observa-se uma menor quantidade de iniciativas em algumas organizações, porém com mais consistência. As aplicações estão mais bem pensadas e mais profundas. Por isso, eu diria que IA seria o primeiro ponto a destacar.Não vai ter uma única resposta para essa pergunta. Mas, observando diversas empresas, eu posso dizer que existem situações que variam de zero a um milhão. Há empresas muito empolgadas com a tecnologia, que estão apostando bastante e onde todos estão se movimentando para acompanhar. Entre essas, ocorre o que mencionei anteriormente. Algumas, por estarem tão entusiasmadas com a tecnologia, acabam atropelando esse momento inicial da adoção.Em certo sentido, isso não chega a ser um problema, porque é natural que exista essa empolgação inicial, especialmente no caso da IA, que foi uma tecnologia amplamente discutida fora do ambiente de tecnologia. A IA ultrapassou barreiras. Diferente de outras tecnologias, como blockchain ou IoT, que tinham conversas concentradas em nichos específicos, IA passou a ser tema de conhecimento geral. Você conversa sobre IA com um familiar distante da área e a pessoa sabe do que se trata, mesmo que não consiga explicar. Ela realmente ultrapassou essa bolha.Por isso, é natural que algumas empresas com um viés tecnológico mais forte tenham um início acelerado e até um pouco desorganizado, mas acredito que isso se ajusta ao longo do processo. Se a empresa tem maturidade digital e pessoas qualificadas para organizar essa movimentação, tudo tende a se estabilizar.Esse é um extremo. No outro extremo, existem empresas que permanecem em um estado de negação tecnológica, com muita resistência interna. Outro fator importante nesse grupo é que, muitas vezes, essas empresas até desejam adotar a tecnologia, mas não têm a base necessária. IA é um tema que chegou para todos. Mesmo em empresas menos antenadas, é impossível que as pessoas não tenham ouvido falar. Mas, ao olhar internamente, percebem que não possuem o mínimo para aplicar a tecnologia de forma prática. Falta uma base de dados adequada, maturidade de infraestrutura ou outros elementos essenciais.Assim, existe também uma barreira de adoção que é intraorganizacional, relacionada à própria forma como a empresa está estruturada, como os sistemas foram implementados e como está sua bagagem digital. No Brasil, observamos todos esses cenários, com variações por segmento. Em setores tradicionalmente tecnológicos, como o financeiro, isso se manifesta de forma muito clara. Eu costumo dizer que, dentro de um banco, TI é o equivalente ao chão de fábrica.Já atuei em alguns setores e vou destacar alguns: aeronáutico, consultoria em tecnologia, serviços financeiros e saúde. Comecei minha carreira em uma função operacional e depois migrei para a área de desenvolvimento.Trabalhei com tecnologias tais como Java, PL/SQL; trabalhei bastante com ABAP, com C#, C++, entre outros. Trabalhei com diversas tecnologias no que tange à área de ERP e à integração de sistemas. Na empresa do setor aeronáutico, eu fui de tech lead, desenvolvedor de tech lead e arquiteto de soluções, onde tive a oportunidade de fazer o programa de especialização em engenharia de dados da companhia.Hoje, forma mais de 200 pessoas por ano, então acho que é um ponto importante a gente ressaltar. Na área da saúde, eu tive uma passagem como arquiteto enterprise e como arquiteto de soluções. Então eu ficava focado em fazer desenhos macrofuncionais, técnicos e também de arquitetura de soluções.Então eu tive essa grande oportunidade de trabalhar também com o mercado de Open Health. Hoje, como sou gerente de tecnologia no setor financeiro, trabalho com o corpo de arquitetos sênior e especialistas. Hoje trabalhando com algumas verticais de negócios, entre os quais investimentos, seguros, consórcio de capitalização, entre outras.Além de tudo isso, eu também tenho uma carreira acadêmica. Apesar da idade de 38 anos, já tei aula ali e lecionei por 10 anos, durante a minha trajetória profissional, em duas grandes universidades aqui do Vale do Paraíba. Fico localizado no Vale do Paraíba, apesar de minhas atuações, as duas últimas, podendo destacar aqui na capital de São Paulo.Nos setores em que trabalhei e que pude acompanhar, destaco a Embraer, a DASA e o Santander. A Embraer, além de ser uma empresa de tecnologia, tem um foco muito forte em se tornar uma organização data-driven. Trabalhar com dados e com machine learning é prioridade em qualquer companhia do setor aeronáutico, porque hoje é o principal tema quando se fala em evolução baseada em dados.Hoje, com base em dados, você evolui produtos. Eu vivenciei isso e fui um dos responsáveis por direcionar a companhia estrategicamente para esse patamar.Na DASA, a empresa possui um dos maiores data lakes da América Latina no setor de saúde.Considerando a estratégia voltada ao cliente, destaco como principais tecnologias a integração de dados e a inteligência artificial.No Santander, além de machine learning e LLM, fala-se bastante em inteligência artificial. Mas, independentemente disso, é essencial trabalhar e valorizar a estratégia no contexto de dados e de arquitetura de soluções.Hoje, eu vejo que é um diferencial, como eu posso dizer, de um fator estratégico. A companhia atualmente está passando por uma transformação, e posso dizer que isso envolve tanto aspectos tecnológicos quanto culturais, para ampliar o conhecimento. É um ponto interessante de comentar.A adoção dessas tecnologias está diretamente ligada ao conceito de cultura. Existe sempre a ideia de que é preciso fazer algo para estar preparado para o próximo passo. Tenho observado um movimento interessante de alguns pares e níveis de liderança buscando esse entendimento.É uma imersão que orienta a companhia para esse novo passo tecnológico. Hoje existe um olhar diferenciado para organizar esse novo conjunto de capacidades necessárias para esse tipo de operação.Faço apenas um ponto dentro de algumas estratégias pelas quais passei. Vejo que a adoção é semelhante à estratégia de um data owner dentro de uma cultura e de uma abordagem data-driven.Dentro desse contexto, quando você diz a alguém que ela é um data owner, até mesmo a um C-level, isso cria um bom comparativo. A adoção tecnológica passa pelo filtro da cultura e, quando todos começam a falar e respirar o mesmo tema, isso se torna parte da companhia.Muitas vezes isso também depende da forma como o CIO e o CTO estão posicionados.Os demais C-levels também têm um grau de comparação. Muitas vezes, a adoção precisa seguir duas estratégias: bottom-up ou top-down, dependendo da situação.A maior dificuldade é o desconhecimento e, de certa forma, o receio sobre o impacto para quem está envolvido no processo. Quando falo em impacto, é no sentido de querer dar um próximo passo tecnológico sem ter pleno entendimento e sem saber o que isso pode se tornar no futuro.Hoje vivemos alguns dilemas e, em outras regiões do mundo, esses dilemas já estão sendo enfrentados de forma mais direta.A falta de conhecimento e a dificuldade em enxergar a relação entre o que se faz agora e o resultado final podem ser pontos frágeis dentro da cultura organizacional.Quando todos estão alinhados no mesmo contexto, o avanço tende a ser mais consistente.Sou formado em Administração e Sistemas de Informação. Concluí minha formação em Munique, e meu primeiro emprego na área foi em uma startup do Vale do Silício que desenvolvia um banco de dados open source, onde entrei ainda no início do projeto. Fiquei lá por cinco anos, até a empresa ser adquirida.Em 2012, mudei-me para o Brasil e fundei uma startup de e-commerce, atuando como CTO. Em 2017, entrei no ambiente corporativo, passando a trabalhar com dados e data science no Grupo Expedia. Comecei no e-commerce, mas depois assumi uma nova área focada em IA e automação de análises.Em 2019, fui para a Cogna como Head de dados Analíticos e IA, com a missão de estruturar um time de dados do zero.No final de 2020 e início de 2021, entrei no Grupo Boticário para construir toda a área de dados e IA também a partir do zero. Atuei inicialmente como diretor e, posteriormente, como diretor executivo. Foi uma iniciativa de muito sucesso, tornando-se um case amplamente reconhecido no varejo.Saí no final do ano passado e me tornei consultor, atuando junto a grandes empresas e suas diretorias para ajudá-las a estruturar planos completos de dados e IA. Em alguns casos, o foco é self-service analytics; em outros, estratégias de ativação e uso de dados, ou ainda como iniciar a jornada de IA, transformar pilotos em resultados reais e organizar tudo dentro de um plano coerente.No meu setor, falando especificamente sobre IA e dados, certamente a IA generativa e a agent-AI têm se destacado. Essas tecnologias estão transformando aquilo que antes dependia exclusivamente de modelos tradicionais de IA baseados em dados e, de certa forma, canibalizando parte do desenvolvimento de software.Isso não afeta apenas o desenvolvimento, mas também áreas como leitura e análise de documentos, medicina, advocacia e várias outras.Na área de software, que até dois anos atrás era vista como uma carreira extremamente segura, com demanda garantida, essa realidade está mudando muito rápido, não apenas para profissionais júniores, mas também para sêniores.Com a busca das empresas por eficiência, acredito que essa é a tecnologia que mais vem causando disrupção no status quo.Eu enxergo ainda muito baixo. Eu acho que as pessoas usam, e a gente já tinha no sentido de ChatGPT, GitHub Compilator Cursor, eles usam, mas no nível pessoal, para facilitar o próprio trabalho, mas não no nível organizacional, numa esteira que conecta tudo. A gente fala sobre agentes IA, é muito ainda copy-paste, ferramentas isoladas, mas não tem uma arquitura, um plano, um processo que conecta isso ponta a ponta, vamos dizer.Poucas empresas têm. Eu vejo mais em startups que eles estão mais avançados, mas as grandes empresas, muitos nem passaram pela transformação digital. Muitos nem são digitais.Isso não tem relação apenas com tecnologia, mas principalmente com a forma como a organização está estruturada, como trabalha e como a área de tecnologia se posiciona."Primeiro, há uma questão de entendimento. Falo aqui do alto nível, das pessoas que tomam a decisão de fazer ou não fazer. Os desenvolvedores e os perfis técnicos entendem bem, mas quem realmente paga a conta, aprova investimentos e define a estratégia muitas vezes não compreende a dimensão do que já está acontecendo e de como tudo está mudando.Além disso, falta um plano, uma estratégia de médio e longo prazo, e principalmente a execução consistente desse plano. Vejo muitas empresas trabalhando apenas com pilotos, testam uma ferramenta aqui, outra ali, mas nada se conecta. Surgem vários pilotos, poucos avançam, e quase nenhum escala.Portanto, é muito mais uma questão cultural. A empresa precisa amadurecer em entendimento e cultura para conseguir evoluir.Eu trabalho com tecnologia há quase 25 anos. Comecei ainda na faculdade, programando como developer, e segui a carreira passando por todas as etapas: developer, arquiteto, líder, coordenador e gerente. Acho importante destacar as três experiências mais recentes, que são as mais relevantes para a nossa conversa.Passei bastante tempo no Grupo Boticário, onde liderei uma transformação importante de conexão da indústria com o varejo e do varejo com o consumidor. Envolvia arquitetura, dados, criação de barramento, microserviços, desacoplamento de monolitos e desenvolvimento de produtos digitais como e-commerce. Entre os projetos estratégicos, destaco o Omnichannel, que conectou as 4 mil lojas ao e-commerce usando Picap Store e ChipFone Store, permitindo que os franqueados atuassem na última milha. Também liderei o laboratório de inovação, o Bot Labs, focado em experimentação e inovação, que depois evoluiu para um Venture Capital que investe em startups.Depois, tive uma passagem relevante pela Petrobras, onde liderei toda a área de transformação digital, composta por tecnologia, produtos digitais, métodos ágeis, centro de excelência de robotização e digitalização de processos e a academia de transformação digital. Era um ambiente altamente complexo, com muita geração de valor e forte uso de dados e inteligência artificial antes do hype. Para ilustrar, havia desafios como identificar corretamente os poços para perfuração, e os algoritmos eram fundamentais para calcular tamanho de reservatórios, espessura e tipo de broca, com base nas amostras perfuradas. Era inteligência artificial aplicada de forma profunda, não generativa.Depois disso, atuei no Grupo Portobello, que possui fábrica e distribuição nos Estados Unidos, forte presença de varejo no Brasil com a Portobello Shop, lojas próprias e franquias, além de fábricas em Santa Catarina e no Nordeste. A empresa abastece home centers, engenharias e exporta para mais de 40 países. O grupo tinha um desafio grande de transformação digital, desde estruturar dados e produtos digitais até barramentos, microserviços e o desenvolvimento de soluções de maneira consistente.Cara, tecnologia tem bastante, acho que tem muito, mas olhando para a escala, o cloud, para mim, foi um avanço, porque antes vivíamos em movimentos de data centers locais ou de data centers de operadoras que não ofereciam muitos serviços. Com o advento das nuvens, isso trouxe muita escalabilidade. Pensando em como escalar a tecnologia, estrangular os legados e os monolíticos e conseguir gerar valor, o cloud foi muito importante.Também houve um movimento forte, não tão novo, das aplicações distribuídas em microserviços, o que trouxe uma força muito grande para gerar valor para o cliente. Antes era tudo em cima daquele modelo tradicional monolítico, e não dava para fazer melhorias com velocidade. Isso trouxe rapidez e responsividade, até para a criação de aplicativos e páginas responsivas.E a AI, com a qual já trabalho há bastante tempo, desde quando não era famosa, já permitia fazer modelos preditivos, manutenção preditiva e prever vendas. Isso sempre existiu. Agora, com a nova onda de Gen AI, alcançamos outro patamar.Então, para mim, pensando de imediato, gosto sempre de destacar três coisas, e essas três foram bem importantes, embora exista muito mais.Onde eu passei, tive o privilégio de ser contratado para isso. Eram empresas que estavam em um momento mais parado, se sentindo ultrapassadas e sem conseguir gerar valor. Meu mandato sempre foi esse. Então, Cloud First, produtos digitais e AI, muito. Esse sempre foi um mandato muito forte. As adoções sempre foram 100%. Nunca tive restrição para nada.Acho que existe um trabalho muito legal dos parceiros, como Microsoft, Google e AWS, em investir em quem está começando. Sempre usei muito isso e sempre foram parceiros importantes nessa jornada, ajudando bastante. A resistência foi zero. A adoção sempre foi a máxima possível.A principal dificuldade é o fator humano. Para mim, o maior desafio é convencer pessoas que estão há muito tempo exercendo suas atividades da mesma forma. Em muitas empresas, alguém é contratado para orientar mudanças e diz que é preciso fazer de determinada maneira, porque a organização já avançou para esse estágio. Ainda assim, o ponto mais sensível continua sendo as pessoas.O segundo ponto é o financeiro. Vivemos em um país onde a economia oscila bastante. Em alguns momentos há recursos disponíveis e, em outros, não. Embora tenha havido um impulso durante a pandemia, quando todos precisaram investir para manter as operações, o orçamento ainda é um aspecto que impacta diretamente, já que costuma ser o primeiro alvo de cortes.O terceiro ponto é demonstrar valor. Depois de convencer as pessoas e garantir recursos, é necessário mostrar como a iniciativa impacta o negócio. É preciso evidenciar como determinado indicador saiu de uma situação negativa para uma melhor, como houve aumento de vendas ou redução de efetivo, e quais indicadores de negócio foram influenciados. Muitas vezes se utiliza tecnologia apenas por utilizar, o que gera frustração e reduz o interesse da empresa em continuar investindo. De forma objetiva, considero que o primeiro desafio é o fator humano, o segundo é o investimento e o terceiro é a capacidade de comprovar o valor gerado.Eu me formei em computação na Universidade Federal de Viçosa, concluí ciência da computação na mesma instituição e, posteriormente, fiz mestrado em algoritmos com ênfase em otimização combinatória na PUC do Rio. Na PUC, tive a oportunidade de conhecer meu professor, que foi meu orientador, e outro professor colega dele. Eles me convidaram para montar uma empresa, nós montamos essa empresa e ela permaneceu ativa até 2015, quando foi adquirida pela Accenture.Em 2015, passei então a ser empregado da Accenture e atuei como diretor de analytics até 2019. Em 2019, vim para a Vale assumir a posição de gerente de tecnologia para ferrovia e porto. Em 2023, fui promovido para o cargo que ocupo atualmente, de head de inteligência artificial e democratização de dados.Eu vou dividir minha resposta nessas duas vertentes. Do ponto de vista de captura de benefício, quando falamos de machine learning ainda existe um campo muito grande a ser explorado na indústria de mineração. Há muito potencial para capturar benefício financeiro com machine learning. E machine learning envolve diversos algoritmos, auto machine learning e várias outras possibilidades que podemos aplicar.Do ponto de vista de mídia, é a Gen AI. Desde que a Gen AI surgiu, desde que a OpenAI lançou o ChatGPT em novembro de 2022, esse se tornou o assunto mais falado e comentado. A companhia já colocou em produção algumas soluções que utilizam Gen AI, mas a verdade é que, em termos de captura de benefício financeiro, machine learning tem gerado muito mais resultado até agora.A programação linear inteira e a metaheurística capturam bastante benefício. Temos o planejamento de scheduling dos viradores de vagão, o planejamento de scheduling de cruzamento de trem na ferrovia, porque apesar de termos ferrovia duplicada, quando ocorre manutenção a ferrovia se torna singela naquele trecho. Quando isso acontece, é necessário planejar o cruzamento. Também existem pontos, como a ponte do Rio Tocantins, que não é duplicada, então é preciso planejar o cruzamento dos trens na ponte.Para tudo isso utilizamos metaheurística, que captura muito benefício. A metaheurística existe desde a década de 70, já faz bastante tempo. O termo pesquisa operacional começou na década de 40, na Segunda Guerra Mundial. Desde então a tecnologia evoluiu: naquela época os computadores utilizavam válvulas, depois veio o transistor e, posteriormente, os microchips, capazes de executar milhões de cálculos por segundo, com clocks altíssimos. A evolução vem acontecendo desde lá.Isso. A empresa atual, modesta parte, é muito pioneira nas coisas. Eu trabalhava na minha própria empresa, e nós vendíamos para a empresa que estou atualmente desde 2003. Não é 2013, é 2003. Vendíamos planejamento de scheduling para a ferrovia desde 2003. Então, a empresa sempre teve essa característica de estar na frente e de ser early adopter.É difícil afirmar de forma absoluta, mas se você mencionar qualquer técnica, provavelmente serei capaz de citar alguma solução nossa que está rodando em produção utilizando essa técnica. A companhia é muito early adopter em tudo isso.Cara, aí eu vou ser clichê. dados e pessoas. Sobre dados, se eu quiser trabalhar com machine learning, por exemplo, predictive asset mindness, o PAM, que é muito usado para predizer falha de equipamento, eu preciso ter o dados daquele equipamento. Eu preciso ter a telemetria do equipamento. Então, esse equipamento já está sensoriado? Se não estiver, eu preciso sensoriá-lo. Esse é o primeiro ponto. Também preciso ter dados das condições ao redor do equipamento, porque dependendo do equipamento isso é relevante. Ele tomou sol? Chuva? Vento? Poeira? Para conseguir prever a quebra, eu preciso desses dados.Depois de ter esses dados, eu preciso fazer esse dados trafegar do chão de fábrica até a nuvem, onde vou rodar os algoritmos. Aqui na Vale, as redes são separadas. Existe a rede de OTI, onde está o equipamento, e a rede de IT, que acessa a cloud. Entre elas há uma DMZ. Para tirar o dados de lá e levar para a cloud, eu tenho que passar por várias regras de firewall. Então, minha resposta soa clichê, mas é isso.O outro problema é pessoas. As pessoas querem ser relevantes, é um desejo humano, meu inclusive. Quando vou levantar hipóteses para um modelo de inteligência artificial, preciso de um especialista, porque eu entendo de algoritmo, não de negócio. Depois que formulo o modelo, preciso novamente do especialista para verificar se aquilo faz sentido. E depois preciso dele de novo para colocar o modelo em operação.E, quando o modelo começa a rodar, esse especialista pode sentir perda de relevância. Ele tem conhecimento táctil, e quando chega em uma área, todos querem ouvir a opinião dele. Quando ele transfere parte desse conhecimento para o modelo, o modelo começa a responder no lugar dele. Isso pode fazer com que ele não seja mais chamado como antes. O ser humano quer que isso aconteça? Normalmente, não.Com isso, fica difícil ter engajamento das pessoas certas. Eventualmente, podem surgir detratores que não querem que a solução de IA entre. Esses são os maiores desafios: dados e pessoas.E não é um problema tecnológico. Aqui na Vale usamos a cloud da Azure. Dentro da Azure eu posso usar Azure Machine Learning, Llama, Grok, o que quiser. Dá até para usar computador quântico, embora ainda não tenhamos usado. A tecnologia está disponível e fácil de consumir. O problema não é a tecnologia, é dados e pessoas.Sou CIO do Hospital e, anteriormente, atuei em outras verticais de negócio. Fui CIO no grupo ConstruCarte, passando pelas áreas de água e saneamento, além da construção civil, incluindo obras complexas.Participei do processo de verticalização do grupo, em modelos de PPP. Atuei também como CTO e gestor de projetos em verticais como o Mineirão, na restauração para a Copa do Mundo, e na vertical de saúde, nas PPPs do estado de São Paulo, com três grandes hospitais, onde também exerci a função de CIO.Além disso, trabalhei na vertical de parques, como Ibirapuera e Parque Nacional do Iguaçu, atuando como CTO na Lúbia Parques.Atualmente sou CIO do Hospital Português, em Recife, o maior hospital do Norte e Nordeste, com 850 leitos e uma infraestrutura de aproximadamente 9 mil usuários.Eu acho que dentro do conceito de transformação digital, a gente poderia citar a própria inteligência artificial, desde a generativa, ou os modelos mais tradicionais, que nem têm o conceito direto de IA, uso de RPA, muito forte também, uso de robôs para fluxos de aprovação, autorização, elegibilidade.Também, dentro do conceito de transformação digital, tecnologias de autoatendimento, com o uso de tokens, aplicativos, apps e super apps, para a consolidação da jornada do paciente, colaboradores e equipe médica também, são as que eu acho que têm mais se destacado.Hoje, no hospital, isso está em fase de imersão. Estamos em um projeto que completa um ano, chamado Prédio Sinapse, cujo objetivo é implementar transformação digital nas jornadas do paciente, do colaborador e da equipe médica.O foco é entender essas jornadas e identificar como a tecnologia pode eliminar atritos, permitindo que os tempos e movimentos dentro da instituição sejam menos burocráticos e administrativos e mais assistenciais.Costumamos dizer que o objetivo é colocar o paciente no centro do cuidado, mas ele ainda passa muito tempo no centro da burocracia. Gasta-se muito tempo com fluxos e processos administrativos pouco integrados, quando o foco deveria ser o cuidado.Esse é o grande propósito do projeto. Estamos em um ramp-up.Acho que as principais questões são culturais e de processo. Costumo dizer que a tecnologia, por si só, hoje não é o grande diferencial.O diferencial está na habilidade de entender os processos e de convencer as pessoas a adotarem novas tecnologias, que muitas vezes precisam vir acompanhadas de melhorias nos próprios processos.Não adianta fazer transformação digital em um processo pouco eficiente, porque isso apenas acelera algo que já não funcionava bem e pode gerar um efeito rebote indesejado.Estou há 30 anos na área de tecnologia, atuando principalmente no setor financeiro. Sempre procuro impulsionar iniciativas de inovação, conciliando a operação do dia a dia o run the bank com ações voltadas para transformação e modernização o change the bank.Entre os principais projetos que conduzi recentemente, destaco a implementação de toda a estrutura de Big Data e Cloud no banco Safra. Antes, a arquitetura de dados era descentralizada, com processamento departamental e servidores locais. Realizei um trabalho de consolidação em uma plataforma de Big Data, que se tornou o primeiro projeto em nuvem do banco Safra, adotando inclusive uma estratégia multi-cloud. Posso detalhar mais sobre essa experiência, se houver interesse.Também tive contato direto com o tema de inteligência artificial. Implantei algumas soluções de IA no próprio banco Safra e aprofundei meus conhecimentos com viagens de estudo à China e ao Vale do Silício, acompanhando de perto o avanço das tecnologias nessa área. Estive no Vale justamente no dia do lançamento do DeepSeek, o que me permitiu observar de perto a movimentação do mercado.Posteriormente, fundei uma startup voltada à aplicação de inteligência artificial no setor financeiro. Primeiro, falando de um passado recente, destaco o movimento de digitalização. Essa transformação foi muito marcante no setor financeiro: levamos praticamente tudo para o digital, tirando o cliente da agência e trazendo a mobilidade para o celular. Isso trouxe praticidade para o cliente, eficiência para o banco e ainda uma camada extra de segurança com o uso do dispositivo móvel e técnicas de antifraude bem estruturadas, conseguimos proteger melhor o cliente e seu dinheiro. Essa foi, portanto, a primeira grande transformação: o digital e o mobile.A segunda foi a adoção da computação em nuvem. A cloud trouxe mais dinamismo e eficiência financeira para as instituições, desde que implementada de forma estratégica não basta simplesmente “mover tudo para a nuvem”.A terceira grande mudança foi o avanço do Big Data e de todo o ecossistema de ferramentas de dados. Essas três  digitalização, cloud e Big Data estão completamente interligadas e se fortalecem mutuamente.A quarta, e talvez a mais relevante no momento, é a inteligência artificial. Embora não seja uma tecnologia nova, ela já traz valor há bastante tempo para o setor financeiro, especialmente em temas como antifraude e modelos de risco. A diferença é que agora estamos em uma nova fase, com o uso intensivo de machine learning, o que amplia bastante as possibilidades de aplicação.Entre as tecnologias mais recentes, mas que ainda não se provaram completamente, cito a tokenização. Analisei e trabalhei com o tema, inclusive liderando iniciativas de directs no Safra, mas, do meu ponto de vista, ainda não vi aplicações que realmente tragam valor por si só. A tecnologia faz sentido, mas para gerar impacto real é preciso uma redefinição profunda dos processos e de toda a cadeia envolvida.Por exemplo, no setor imobiliário, seria necessário repensar toda a estrutura de cartórios e regulamentações há muitas barreiras políticas e operacionais. Então, é uma boa tecnologia, com potencial, mas que ainda busca seu espaço, diferentemente da inteligência artificial, que já demonstrou valor prático logo de início.Bom, primeiro tem a questão da velocidade tanto do ponto de vista das empresas quanto dos clientes. Algumas tecnologias evoluem rápido, mas é preciso respeitar o tempo delas. Não basta ter a boa ideia, é preciso também existir uma demanda concreta no mercado.Um exemplo: há algum tempo tivemos o lançamento dos palms, que, basicamente, eram dispositivos móveis, mas sem conectividade. A tecnologia estava ali, mas o mercado ainda não estava pronto para ela. Agora, quando o setor bancário passou a investir nos aplicativos mobile, os clientes já tinham dispositivos compatíveis com o tamanho e a complexidade desses aplicativos. Aí sim houve a sinergia perfeita, o banco pronto para oferecer e o cliente pronto para consumir. Essa sincronia fez com que o mobile banking crescesse e substituísse o internet banking.Então, a empresa pode acelerar, mas o cliente também precisa estar preparado. Esse equilíbrio é essencial.Quando falamos de cloud, por exemplo, houve uma quebra de paradigma importante. No começo, existia muita desconfiança as pessoas achavam interessante, mas tinham dúvidas sobre segurança. Muita gente queria “ver o servidor”, entender onde os dados estavam fisicamente. Isso aconteceu inclusive em grandes bancos. Era comum alguém perguntar: “Certo, eu entendo que é nuvem, mas onde está rodando? Como eu tenho certeza de que meus dados estão seguros e que outra instituição não vai acessá-los?”Depois que essa barreira foi superada, as empresas começaram a adotar cloud, mas de forma gradual geralmente com sistemas menos críticos. Na empresa, por exemplo, por ser um banco mais conservador, a transição foi feita com muito cuidado. Eu sabia que esse era o futuro, mas entendi que o momento certo era fundamental. Então, fiz o trabalho de base: me preparei, selecionei bem o primeiro projeto a migrar e construí toda a estrutura de segurança necessária para que o banco se sentisse confortável com o movimento.De nada adianta definir uma estratégia de migração para cloud se a instituição não tiver confiança técnica e controles adequados. Mesmo que as grandes provedoras, como a AWS, tenham alta disponibilidade e mecanismos de mitigação por zonas, ainda existe o risco, mesmo que remoto, de falhas ou vazamentos. Em um banco que trabalha com clientes de alto patrimônio, qualquer brecha pode representar uma quebra de confiança.Por isso, desenvolvi um conceito de multi-cloud, para reduzir ao máximo a dependência de um único fornecedor o que chamamos de lock-in. É impossível eliminar totalmente, mas dá para minimizar. Essa foi a estratégia que adotei: mitigar o risco de concentração, distribuindo a operação em diferentes nuvens.Então, em resumo, a adoção dessas tecnologias depende de dois fatores principais:primeiro, o nível de risco que a empresa está disposta a assumir, e segundo, a prontidão, tanto do fornecedor quanto de quem vai consumir a tecnologia, seja o mercado ou o cliente final.Depois, depois que eu entrei na Unicamp, na faculdade, aí eu passei pela indústria alimentícia, foi a minha única experiência na indústria. Depois eu já fui para o setor financeiro e agora para o educacional.Sim com todas as siglas, né? BI, CNN, MIS. É, sim.Hoje estamos bastante focados em inteligência artificial, que é o grande destaque do momento, mas também já acompanhamos de perto os avanços em computação quântica. Além disso, tudo o que envolve a jornada para a nuvem continua sendo essencial — especialmente as estratégias de gestão e arquitetura de dados, como o data mesh, que traz uma metodologia estruturada para implementação.Portanto, além dos fundamentos de cloud, eu destacaria principalmente IA e, mais recentemente, computação quântica como áreas de maior atenção.A IA, assim, já democratizou, na verdade democratizou antes de chegar nas organizações, chegou aos celulares, né, a população, vou colocar assim. Ainda as empresas não conseguiram tirar muito proveito da IA, embora todas estejam fazendo alguma coisa. Passamos por algumas fases, uma fase inicial de olhar diretamente a eficiência, porque o mato era muito alto, então tem muita oportunidade, tinha e tem, continua tendo.Depois, passaram a ter os experimentos com as áreas de negócio, então foram feitos várias plots, né, ali pra testar o uso da IA. E agora começa, somente agora, começa a escalar isso dentro das organizações maiores, as pequenas ainda estão fazendo experimentos. E aí, uma vez que isso começa a ser mais democratizado dentro das organizações, então começa a ser estabelecida a governança do uso da IA.Então essa é a fase. Computação quântica, a gente está muito embrionário, mas as empresas maiores já estão fazendo testes com a Microsoft, IBM, enfim, quem já tem a máquina, né, e pra poder desenvolver alguns testes, e as pequenas ainda nem começaram a olhar pra isso.Existem vários fatores, mas acho que os principais são os seguintes. Falando em dimensões, atendemos tanto grandes empresas quanto empresas menores. As pequenas, de médio porte para baixo, como seguradoras, cooperativas de crédito e outras organizações desse porte, ainda têm muita dificuldade em implementar a infraestrutura, começando realmente pela base. As grandes já iniciam esse movimento, mas ainda têm muitas dúvidas sobre segurança e sobre a confiabilidade das soluções que estão sendo desenvolvidas.Ainda é necessário evoluir nesse ponto. É comum desenvolver um robô que deveria oferecer produtos de um banco e acabar oferecendo produtos de outro, o que é uma alucinação. Então, ainda existe uma questão de confiança que precisa ser fortalecida. Também há o desafio relacionado à capacitação. Como tudo é muito recente, há muitos profissionais que se posicionam como especialistas, mas ainda estão aprendendo, alguns com mais habilidade e outros com menos.De forma geral, eu colocaria que, para as empresas de médio porte para baixo, os principais fatores são infraestrutura e investimento. Para as empresas de grande porte, o ponto central é a confiança, especialmente no que diz respeito à segurança necessária para utilizar essas tecnologias e oferecê-las ao mercado.Eu trabalho com dados e inteligência artificial há pelo menos oito anos de forma intensa. Sou cientista de dados e fui me especializando em IA ao longo da carreira. Comecei com dados quando estava concluindo a graduação, atuando como cientista de dados na Gerdau, na indústria do aço. Na época ainda não havia IA generativa, isso há aproximadamente nove ou dez anos. Usávamos principalmente algoritmos de predição, classificação e modelos de machine learning, sempre exigindo uma preparação significativa dos dados.Sem entrar ainda na parte técnica, falando apenas das passagens profissionais: na Gerdau desenvolvi algoritmos de otimização de malha rodoviária e ferroviária, pois entrei pela área de logística. Atuava como cientista de dados trabalhando diretamente com dados logísticos, o que foi uma experiência muito interessante.Depois fui para o Carrefour, também como cientista de dados, atuando diretamente com a CDO da companhia. Era um ambiente com forte expectativa em relação ao uso de Big Data para análises e algoritmos mais sofisticados. Porém, o Data Lake ainda não estava pronto, então tivemos de retroceder, focar primeiro em Data Quality e só então avançar para ciência de dados e IA de forma consistente.Em seguida, fui para o Santander trabalhar com NPS, aplicando IA nessa métrica crítica para o banco, que influencia diretamente a recomendação do cliente e a remuneração variável dos funcionários. Havia muitos desafios relacionados a dados e infraestrutura legada, com bancos de dados não hospedados em cloud e sem Data Lake, além de toda a complexidade da infraestrutura bancária. Foi uma experiência bem diferente, que me atraiu justamente pela diversidade de segmentos e estruturas tecnológicas.Depois dessas passagens pela indústria de aço, varejo e setor financeiro, cheguei à empresa onde estou há dois anos e um mês. Em breve iniciarei uma transição. Na empresa atual já existe um Data Lake bem estruturado com dados provenientes de muitos sistemas. Atuo como Head de Inteligência Artificial, posição criada devido à necessidade de especialização após o avanço da IA generativa nos últimos anos. A empresa já dominava IA tradicional e machine learning, mas a IA generativa trouxe novas possibilidades e também novos riscos.Estou há 18 anos na área de tecnologia. Depois que deixei o desenvolvimento e me apaixonei pela área de dados, tornando-me cientista de dados, essas foram as passagens mais marcantes da minha trajetória.Certo, a Inteligência Artificial Generativa realmente trouxe um grande salto. Passamos por um momento em que grande parte das pessoas acreditava que Inteligência Artificial era restrita às academias e às grandes empresas, algo distante e caro. A IA generativa, especialmente com os LLMs, levou essa tecnologia para as mãos da população e quebrou muitas barreiras. Hoje muitos acreditam que conseguem criar soluções de IA e extrair valor, o que, em parte, é verdade, desde que haja orientação adequada e conhecimento do que está sendo feito.A computação quântica também vem ganhando espaço, mas ainda com muitas ressalvas. Existe um excesso de mídia em torno do tema e nem tudo o que se fala se materializa no ritmo esperado. As empresas estão investindo, mas os avanços ainda são controlados. No futuro, porém, pode haver uma disrupção significativa, já que muitos sistemas que usam criptografia e funcionam hoje podem deixar de funcionar com a chegada da quântica, o que trará novos desafios.Esses são os dois principais movimentos: a IA generativa nos últimos dois ou três anos e a computação quântica tentando disputar parte desse protagonismo.Com a IA generativa, desde 2022, todas as empresas iniciaram uma corrida intensa para adotar a tecnologia. Muitas querem usar a IA generativa de qualquer forma e para qualquer finalidade, o que tem criado um grande movimento no mercado. No entanto, ainda é difícil comprovar o retorno sobre o investimento, já que o valor efetivo gerado pelas iniciativas nem sempre é claro. As empresas estão explorando possibilidades, consultorias e big techs têm ofertado produtos pré-formatados, mas o nível de maturidade ainda é baixo. A maior parte das organizações está apenas saindo da fase de experimentação e começando a colocar os primeiros MVPs em produção.Mesmo em grandes companhias, os casos em produção ainda são poucos e, muitas vezes, limitados a públicos específicos, justamente para manter controle e reduzir riscos. A IA generativa, quando interage diretamente com clientes externos, pode expor a empresa a riscos de reputação caso entregue informações imprecisas. Por isso, é comum observar a adoção de modelos híbridos que combinam IA generativa com outras tecnologias, como algoritmos tradicionais, automações e diversos componentes de engenharia de software. A generativa atua na camada conversacional, permitindo que o usuário faça solicitações em linguagem natural, mas o processamento crítico é feito por mecanismos determinísticos, com regras claras e consultas específicas a bancos de dados. Depois, a resposta é novamente convertida para linguagem natural.Na prática, o usuário tem a impressão de que a IA generativa realiza todo o processo. É como perguntar pelo saldo bancário em um chatbot e acreditar que o modelo acessou diretamente o banco e trouxe a informação. O que realmente acontece é uma combinação de tecnologias, com muitas proteções para evitar erros e garantir que dados sensíveis, como saldos de contas, não sejam expostos incorretamente.Mas, se eu tentar sacar esse dinheiro, não vai funcionar e eu estarei sendo iludida. Isso mostra o risco envolvido. As empresas já estão combinando várias tecnologias nos projetos para entregar o resultado final, com foco muito maior na experiência do cliente e do usuário.A experiência desejada pelo usuário, por exemplo, é fluida. Ele quer entrar em um site, acessar tudo em uma única tela, perguntar o saldo bancário, contratar um empréstimo, pagar um boleto em linguagem natural e ir conduzindo a interação enquanto diversos agentes e sistemas, encadeados por trás, resolvem cada solicitação a partir dos comandos que ele fornece em linguagem natural.As empresas estão buscando oferecer esse tipo de experiência fluida com o uso da IA generativa, mas ainda existem muitos gargalos relacionados a segurança, integrações sistêmicas e prontidão dos dados, temas que vamos aprofundar posteriormente.Existem desafios sistêmicos, porque há muitos sistemas legados e, muitas vezes, as pessoas acham que é só “plugar” a IA em cima. Em vários casos, esses sistemas nem têm conectores, nem API, não são simples de integrar, são sistemas antigos, mais “cavernosos”, ainda em uso e que, para o propósito para o qual foram criados, são excelentes. Porém, para esta nova era em que o desejo é conectar tudo com tudo, eles dificultam bastante.Há também o tema da prontidão dos dados. Ainda existe a ideia de que basta pegar todos os dados transacionais, jogar em um grande data lake, estruturado em tabelas com dados brutos, colocar IA em cima e tudo vai funcionar muito bem. Isso não é verdade. A IA precisa de contexto, precisa entender que dados é aquele e, além disso, precisa de uma camada de tratamento com contexto de negócio. Muitas vezes o dados bruto está cheio de siglas e códigos e, como usuária ou usuário, quero perguntar em linguagem natural e esperar que, no banco de dados, tudo seja resolvido de forma que aquela sigla ou código corresponda ao produto específico sobre o qual desejo saber.Todos esses joins entre tabelas, as transformações, a organização dos metadados e as regras de negócio aplicadas precisam estar claros e disponíveis para que a IA consiga entregar o resultado final que as pessoas esperam. E nem toda empresa, nem todas as pessoas, estão dispostas a trilhar essa jornada de entender, primeiro, qual problema querem resolver. Há muito apetite por “usar IA por usar IA”, sem ter um problema bem definido, o que já é um primeiro obstáculo.Quando se tem um problema claro, a próxima etapa é: tenho dados. Onde esses dados estão? Em que condição eles estão? Qual será a jornada necessária de organização desses dados para que fiquem em condição de prontidão para a IA, de forma que o modelo consiga consultá-los, compreendê-los e interpretá-los do jeito que se deseja, respeitando o contexto de negócio. Muitos vieses estão na cabeça das pessoas, mas não aparecem explícitos no dados cru armazenado no banco.E dentro desses grandes modelos de linguagem que já foram treinados, a maioria das empresas acaba usando os modelos como eles vêm, principalmente pelo custo de realizar um treinamento completo ou um fine-tuning. Por isso, recorrem a outras metodologias para contornar vieses e limitações, inserindo informações adicionais e usando abordagens como RAG para incorporar dados próprios da empresa. Isso ajuda o modelo a não depender apenas dos dados originais de treinamento, que podem carregar outros tipos de vieses, e também permite que ele compreenda melhor o público, os dados e a realidade em que será aplicado. Essa adaptação traz o modelo para uma atuação mais alinhada ao contexto específico da empresa. É quase como dizer: entendi que você foi treinado com este universo de informações, mas aqui você precisa se comportar de outra forma.Aqui, na minha empresa, é necessário que o modelo entenda quem é o nosso público e a forma como costumamos nos comunicar. Na empresa, por exemplo, existe o jeito particular de falar, o que inclui orientações sobre o que responder, o que não responder e como abordar determinados temas. Além disso, existem questões relacionadas aos dados, aos vieses e a iniciativas como a presença de mulheres na liderança, que fazem parte do programa amplamente divulgado. Tudo isso precisa ser ensinado ao modelo de alguma forma.Mesmo com um treinamento amplo, o comportamento do modelo ainda é probabilístico e pode destoar do que as pessoas esperam, como você mencionou no exemplo da casta, levando a interpretações completamente diferentes. Por isso, a curadoria humana é essencial em tudo o que é inserido na IA, tanto nos dados usados para dar contexto quanto na revisão das respostas geradas. A curadoria permite identificar quando o modelo não compreende uma expressão, um jargão ou um contexto específico, ajustando a comunicação e aprimorando o entendimento do modelo.Esse refinamento mais preciso só é possível com acompanhamento contínuo, avaliando perguntas e respostas e calibrando o modelo diariamente.Ok, maravilha. Então vamos lá. Eu tenho cerca de 25 a 27 anos de experiência. Comecei muito cedo na área de tecnologia, aos 16 anos, em Curitiba. Trabalhei por bastante tempo em uma empresa de processamento de dados voltada para crédito imobiliário. Depois disso, fui para outra empresa, o HSBC, onde iniciei minha atuação em liderança e arquitetura.Posteriormente, fui para a Alemanha fazer meu mestrado e, ao retornar para Curitiba, atuei por um período na GPT como arquiteto.Depois me mudei para São Paulo, também como arquiteto, e passei pela Monsanto e pela Bayer, assumindo papéis de liderança e Enterprise Architect.Mais adiante, ingressei na Renault, onde estou atualmente. Minha função envolve toda a área digital, incluindo arquitetura, dados, carro conectado, UX, UI e tecnologia.Todo esse escopo que eu que eu que eu cuido agora.Eu acredito que há uma tecnologia que foi bastante subestimada, quase tratada como mais barulho do que algo concreto que foi metaverso. Para mim, o IoT é fundamental, especialmente pelo carro conectado. Hoje, o veículo se torna praticamente um celular ou um dispositivo em movimento, quase como um pequeno Arduino ou Raspberry, enviando mensagens constantemente.Também há tecnologias mais consolidadas, como DevOps e microsserviços, que já estão bem estabelecidas.Além disso, a inteligência artificial não é exatamente nova; utilizamos modelos de machine learning há bastante tempo. Porém, com a chegada dos LLMs e novos recursos, o tema ganhou mais destaque e 'sex appeal', impulsionando novamente a atenção sobre o assunto.Acho que esse é um pouco do ciclo natural de evolução da tecnologia.Hoje, no contexto global, nosso nível de adoção de inteligência artificial é elevado. Porém, localmente, ainda estamos em um estágio de adoção entre baixo e médio. Considerando a perspectiva da América Latina, diria que estamos de pequeno para médio, enquanto globalmente estamos de médio para alto.Isso se aplica às diferentes frentes de uso: desde a aplicação da inteligência artificial dentro do carro, com assistentes que auxiliam na condução e na tomada de decisões, até o lado de negócio.Nessa dimensão, buscamos prever necessidades do cliente e atraí-lo para a concessionária antes mesmo de surgir um problema no veículo, como uma luz de alerta no painel. Também analisamos como o cliente utiliza o carro, com que intensidade, e como isso pode gerar melhores resultados, seja em atendimento, seja em novas vendas.Além disso, utilizamos IA para identificar o público-alvo ideal para cada modelo, otimizar a distribuição da produção no país e garantir que veículos estejam disponíveis nas regiões em que há maior demanda."Quando falamos de inteligência artificial, a disponibilidade dos dados é essencial. Não adianta querer aplicar IA avançada se a base de dados não sustenta isso. Por isso, tivemos e ainda temos um grande trabalho para extrair o dados transacional, processá-lo no data lake e garantir que essa informação saia do transacional, seja por streaming ou outra abordagem, e chegue ao data lake de forma estruturada.A partir daí, conseguimos construir nossas camadas 'gold', que geram resultados relevantes para consumo.A qualidade do dados também é determinante. Muitos sistemas transacionais brasileiros não foram desenvolvidos seguindo padrões básicos de modelagem ou formas normais. Se o dados não foi estruturado corretamente desde a origem, é praticamente inviável utilizar IA de forma eficiente hoje, a menos que se reescreva a base original.Por outro lado, tecnologias como DevOps encaixam bem dentro de modelos bimodais ou multimodais, permitindo identificar nichos onde essa abordagem traz ganhos significativos. O mesmo vale para microsserviços. São tecnologias mais consolidadas, assim como práticas de agilidade, algumas mais maduras, outras menos.